{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from models.FrameNet import MultiResFrameNet, FrameNet\n",
    "from data import VideoDataset, FrameDataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"n_classes\": 5,\n",
    "        \"batch_size\": 1024,\n",
    "        \"lr\": 1e-3,\n",
    "        \"gradient_clip_val\": 0.5,\n",
    "        \"num_epochs\": 50,\n",
    "        \"cnn1_in\": 3,\n",
    "        \"cnn2_in\": 96,\n",
    "        \"cnn3_in\": 256,\n",
    "        \"cnn4_in\": 384,\n",
    "        \"cnn5_in\": 384,\n",
    "        \"cnn5_out\": 256,\n",
    "        \"linear_in\": 4096,\n",
    "        \"dropout\": 0.5,\n",
    "        \"kernel_size\": 3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 14, 14])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,3, 224, 224)\n",
    "cnn = torch.nn.Sequential( torch.nn.Conv2d(3, 32, kernel_size=5, stride=3), torch.nn.MaxPool2d(2), torch.nn.Conv2d(32, 64, kernel_size=5), torch.nn.MaxPool2d(2), torch.nn.Conv2d(64, 128, kernel_size=3))\n",
    "cnn(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrameNet(\n",
       "  (cnn): ConvLayer(\n",
       "    (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(1, 1))\n",
       "    (batchnorm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (fc_net): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=4096, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FrameNet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,3,178, 178)\n",
    "cnn = FrameNet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1673, -0.0653, -0.1619, -0.0608,  0.3181]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\\\n",
    "        transforms.Resize(size=(170, 170), interpolation=transforms.functional.InterpolationMode.NEAREST),\\\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '/home/gaurangajitk/DL/data/sports-video-data/test_images.csv'\n",
    "testset = FrameDataset(pd.read_csv(test_file, usecols=['frame', 'label']), data_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=config['batch_size'], shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 3, 170, 170])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = next(iter(test_loader))\n",
    "first[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = '/home/gaurangajitk/DL/data/sports-video-data/test_videos.csv'\n",
    "videoset = VideoDataset(pd.read_csv(video_file, usecols=['video', 'label']), data_transforms)\n",
    "video_loader = torch.utils.data.DataLoader(videoset, batch_size=1, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = next(iter(video_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 170, 170])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = first[0][0]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 80, 80])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([transforms.CenterCrop(80)])\n",
    "image = data_transforms(image)\n",
    "image.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ee9683fdfa7b35d9efa03fe6c9a658d126a8681914d3f8a30cd0a7db021a5f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cascades')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
